{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%pylab inline\n",
    "pd.options.display.max_columns=100\n",
    "pd.options.display.max_rows=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\analytixlabs\\Complete_datasets\n"
     ]
    }
   ],
   "source": [
    "#importing Dataset\n",
    "\n",
    "os.chdir(\"D:\\\\analytixlabs\\\\Complete_datasets\")\n",
    "print os.getcwd() \n",
    "Telecom=pd.read_csv(\"Proactive Attrition Management-Logistic Regression Case Study.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31047, 78)\n",
      "(40000, 78)\n",
      "Missing values per column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>MOU</th>\n",
       "      <th>RECCHRGE</th>\n",
       "      <th>DIRECTAS</th>\n",
       "      <th>OVERAGE</th>\n",
       "      <th>ROAM</th>\n",
       "      <th>CHANGEM</th>\n",
       "      <th>CHANGER</th>\n",
       "      <th>CSA</th>\n",
       "      <th>AGE1</th>\n",
       "      <th>AGE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31047</th>\n",
       "      <td>38.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>MILMIL414</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31048</th>\n",
       "      <td>55.23</td>\n",
       "      <td>570.50</td>\n",
       "      <td>71.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NNYSYR315</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31049</th>\n",
       "      <td>38.05</td>\n",
       "      <td>682.50</td>\n",
       "      <td>52.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>OKCTUL918</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31050</th>\n",
       "      <td>97.34</td>\n",
       "      <td>1039.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>419.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>23.26</td>\n",
       "      <td>MILMIL414</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31051</th>\n",
       "      <td>35.30</td>\n",
       "      <td>24.25</td>\n",
       "      <td>34.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.75</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>SANMCA210</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31052</th>\n",
       "      <td>81.00</td>\n",
       "      <td>1056.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.75</td>\n",
       "      <td>2.35</td>\n",
       "      <td>PITHOM412</td>\n",
       "      <td>46.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31053</th>\n",
       "      <td>63.02</td>\n",
       "      <td>440.25</td>\n",
       "      <td>59.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-16.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>SLCSLC801</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71040</th>\n",
       "      <td>33.63</td>\n",
       "      <td>28.00</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NEVENC760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71041</th>\n",
       "      <td>85.15</td>\n",
       "      <td>815.00</td>\n",
       "      <td>87.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>LAXVNY818</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71042</th>\n",
       "      <td>117.49</td>\n",
       "      <td>384.00</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>LAXDOW562</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71043</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAXRIV909</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71044</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAXSFN818</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71045</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAXCOR909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71046</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAXCDG310</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       REVENUE      MOU  RECCHRGE  DIRECTAS  OVERAGE  ROAM  CHANGEM  CHANGER  \\\n",
       "31047    38.00     7.50     38.00      0.00     0.00  0.00    -1.50     0.00   \n",
       "31048    55.23   570.50     71.98      0.00     0.00  0.00    38.50     0.00   \n",
       "31049    38.05   682.50     52.49      0.25     0.00  0.00   147.50    -3.06   \n",
       "31050    97.34  1039.00     50.00      4.95   419.50  0.00   198.00    23.26   \n",
       "31051    35.30    24.25     34.98      0.00     0.00  0.00    19.75    -0.31   \n",
       "31052    81.00  1056.25     75.00      0.00     0.00  0.00    42.75     2.35   \n",
       "31053    63.02   440.25     59.98      0.00     5.75  1.31   -16.25     0.21   \n",
       "...        ...      ...       ...       ...      ...   ...      ...      ...   \n",
       "71040    33.63    28.00     29.99      0.00     0.00  0.00     0.00     0.00   \n",
       "71041    85.15   815.00     87.99      0.00     1.00  0.39     0.00     0.00   \n",
       "71042   117.49   384.00     29.99      0.00   250.00  0.00     0.00     0.00   \n",
       "71043      NaN      NaN       NaN       NaN      NaN   NaN      NaN      NaN   \n",
       "71044      NaN      NaN       NaN       NaN      NaN   NaN      NaN      NaN   \n",
       "71045      NaN      NaN       NaN       NaN      NaN   NaN      NaN      NaN   \n",
       "71046      NaN      NaN       NaN       NaN      NaN   NaN      NaN      NaN   \n",
       "\n",
       "             CSA  AGE1  AGE2  \n",
       "31047  MILMIL414  26.0  26.0  \n",
       "31048  NNYSYR315  56.0   0.0  \n",
       "31049  OKCTUL918  28.0   0.0  \n",
       "31050  MILMIL414  38.0  24.0  \n",
       "31051  SANMCA210  36.0  34.0  \n",
       "31052  PITHOM412  46.0  68.0  \n",
       "31053  SLCSLC801  99.0   0.0  \n",
       "...          ...   ...   ...  \n",
       "71040  NEVENC760   0.0   0.0  \n",
       "71041  LAXVNY818  64.0  64.0  \n",
       "71042  LAXDOW562  22.0   0.0  \n",
       "71043  LAXRIV909  34.0  26.0  \n",
       "71044  LAXSFN818  68.0  64.0  \n",
       "71045  LAXCOR909   0.0   0.0  \n",
       "71046  LAXCDG310  36.0   0.0  \n",
       "\n",
       "[40000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Val_Telecom=Telecom.loc[Telecom.CHURNDEP.isnull()]\n",
    "TT_Telecom=Telecom.loc[Telecom.CHURNDEP.isin([0,1])]\n",
    "print Val_Telecom.shape\n",
    "print TT_Telecom.shape\n",
    "\n",
    "def missing(x):\n",
    "    return sum(x.isnull())\n",
    "\n",
    "print \"Missing values per column:\"\n",
    "TT_Telecom.loc[ : ,TT_Telecom.apply(missing, axis=0)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHURNDEP  MCYCLE\n",
       "0.0       0         19736\n",
       "          1           264\n",
       "1.0       0         19706\n",
       "          1           294\n",
       "Name: CUSTOMER, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TT_Telecom.pivot_table(index=['CHURNDEP','MCYCLE'],values='CUSTOMER',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#checking some columns how the missing values look\n",
    "TT_Telecom.apply(missing, axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#removing these 2 columns will give us the base model with any NAs['CALIBRAT' ,'CALLFWDV' ,'CALLWAIT',]\n",
    "\n",
    "TT_Telecom.drop(labels=['CHURN','CALIBRAT' ,'CALLFWDV' ,'CALLWAIT','CUSTOMER','MAILORD','RETCALL','MODELS','MOUREC','BLCKVCE'],inplace=True,axis=1)\n",
    "TT_Telecom.dropna(subset=['AGE1','CHANGEM'],inplace=True)\n",
    "\n",
    "#CSA cant be identified so we we will keep them as missing\n",
    "TT_Telecom.CSA.fillna('Missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31152, 72)\n",
      "(7789, 72)\n",
      "(31152L,)\n",
      "(7789L,)\n"
     ]
    }
   ],
   "source": [
    "X=TT_Telecom.ix[:,:-1]\n",
    "y=TT_Telecom.CHURNDEP\n",
    "#X_test=Val_Telecom.ix[:,:-1]\n",
    "#y_test=Val_Telecom.CHURNDEP\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.20,random_state=0)\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aeb7f40e04f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlbl_enc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlbl_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CSA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlbl_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CSA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_enc=LabelEncoder()\n",
    "lbl_enc.fit(X_train['CSA'])\n",
    "X_train.CSA=lbl_enc.transform(X_train['CSA'])\n",
    "\n",
    "lbl_enc.fit(X_test['CSA'])\n",
    "X_test.CSA=lbl_enc.transform(X_test['CSA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#applying RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier\n",
    "\n",
    "\n",
    "logclf=LogisticRegression()\n",
    "ETclf=ExtraTreesClassifier()\n",
    "adbclf=AdaBoostClassifier()\n",
    "bagclf=BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def features_make80percent(classifier=logclf,)\n",
    "\n",
    "rfe = RFE(logclf, 15)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list=sorted([tup for tup in zip(rfe.ranking_,X_train)])\n",
    "\n",
    "top_features=[col for (rank,col) in feature_list[0:15]]\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fin_X_train=X_train[features[4]]\n",
    "fin_X_train.shape\n",
    "fin_X_test=X_test[features[4]]\n",
    "print fin_X_train.shape\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print fin_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, subsample=.8)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_features': [0.5, 1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(gb, params, cv=10, scoring='roc_auc', n_jobs=4)\n",
    "gs.fit(fin_X_train, y_train)\n",
    "\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(fin_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Metrics\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(classification_report(y_true, y_pred))\n",
    "print '*'*100\n",
    "print \"confusion matrix\"\n",
    "print '-'*100\n",
    "print confusion_matrix(y_true, y_pred)\n",
    "print '*'*100\n",
    "print \"acccuracy Score\"\n",
    "print accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dont Run\n",
    "features=[]\n",
    "for max_features in range(20,30,2):\n",
    "    rfe = RFE(logclf, max_features)\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "    feature_list=sorted([tup for tup in zip(rfe.ranking_,X_train)])\n",
    "    top_features=[col for (rank,col) in feature_list[0:max_features]]\n",
    "    features.append(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train[features[5]]\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC(C=0.1,gamma='auto',kernel='linear')\n",
    "gs = GridSearchCV(svm, params, cv=5, scoring='roc_auc')\n",
    "gs.fit(fin_X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(fin_X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(classification_report(y_true, y_pred))\n",
    "print '*'*100\n",
    "print \"confusion matrix\"\n",
    "print '-'*100\n",
    "print confusion_matrix(y_true, y_pred)\n",
    "print '*'*100\n",
    "print \"acccuracy Score\"\n",
    "print accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# METHOD 2\n",
    "## Feature selection\n",
    "- http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/\n",
    "\n",
    "- Stabilty method \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.0, 'WEBCAP'), (0.0, 'UNIQSUBS'), (0.0, 'UNANSVCE'), (0.0, 'TRUCK'), (0.0, 'TRAVEL'), (0.0, 'THREEWAY'), (0.0, 'SETPRCM'), (0.0, 'SETPRC'), (0.0, 'RV'), (0.0, 'ROAM'), (0.0, 'REVENUE'), (0.0, 'RETCALLS'), (0.0, 'RETCALL'), (0.0, 'RETACCPT'), (0.0, 'REFURB'), (0.0, 'REFER'), (0.0, 'RECCHRGE'), (0.0, 'PRIZMUB'), (0.0, 'PRIZMTWN'), (0.0, 'PRIZMRUR'), (0.0, 'PHONES'), (0.0, 'PEAKVCE'), (0.0, 'PCOWN'), (0.0, 'OWNRENT'), (0.0, 'OVERAGE'), (0.0, 'OUTCALLS'), (0.0, 'OPEAKVCE'), (0.0, 'OCCSTUD'), (0.0, 'OCCSELF'), (0.0, 'OCCRET'), (0.0, 'OCCPROF'), (0.0, 'OCCHMKR'), (0.0, 'OCCCRFT'), (0.0, 'OCCCLER'), (0.0, 'NEWCELLY'), (0.0, 'NEWCELLN'), (0.0, 'MOUREC'), (0.0, 'MOU'), (0.0, 'MONTHS'), (0.0, 'MODELS'), (0.0, 'MCYCLE'), (0.0, 'MARRYYES'), (0.0, 'MARRYUN'), (0.0, 'MARRYNO'), (0.0, 'MAILRES'), (0.0, 'MAILORD'), (0.0, 'MAILFLAG'), (0.0, 'INCOME'), (0.0, 'INCMISS'), (0.0, 'INCALLS'), (0.0, 'EQPDAYS'), (0.0, 'DROPVCE'), (0.0, 'DROPBLK'), (0.0, 'DIRECTAS'), (0.0, 'CUSTOMER'), (0.0, 'CUSTCARE'), (0.0, 'CSA'), (0.0, 'CREDITZ'), (0.0, 'CREDITGY'), (0.0, 'CREDITDE'), (0.0, 'CREDITCD'), (0.0, 'CREDITC'), (0.0, 'CREDITB'), (0.0, 'CREDITAD'), (0.0, 'CREDITAA'), (0.0, 'CREDITA'), (0.0, 'CHILDREN'), (0.0, 'CHANGER'), (0.0, 'CHANGEM'), (0.0, 'BLCKVCE'), (0.0, 'AGE2'), (0.0, 'AGE1'), (0.0, 'ACTVSUBS')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.025)\n",
    "rlasso.fit(X_train, y_train)\n",
    "names=X_train.columns.tolist()\n",
    " \n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), \n",
    "                 names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X_train, y_train)\n",
    "sorted(zip(lr.coef_, \n",
    "                 names), reverse=True)\n",
    "#sorted(zip(lr.rank_,names),reverse=True)\n",
    "lr.rank_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************SCORES**************************************************\n"
     ]
    }
   ],
   "source": [
    "print '*'*50 + 'SCORES'+ '*'*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************SCORES**************************************************\n",
      "Features sorted by their score:\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before `feature_importances_`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-2fe711410f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'SCORES'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Features sorted by their score:\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n\u001b[0m\u001b[0;32m     15\u001b[0m              reverse=True)\n\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'------------'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mfeature_importances_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \"\"\"\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[0;32m    332\u001b[0m                                  \"call `fit` before `feature_importances_`.\")\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before `feature_importances_`."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params={'n_estimators': [100,120,300],\n",
    "        'max_depth': [5,8]}\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "gs = GridSearchCV(rf,params, cv=5, scoring='roc_auc')\n",
    "gs.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "{'n_estimators': 300, 'max_depth': 8}\n",
      "0.660706452466\n",
      "5\n",
      "raise\n",
      "[mean: 0.64682, std: 0.00870, params: {'n_estimators': 100, 'max_depth': 5}, mean: 0.64681, std: 0.00924, params: {'n_estimators': 120, 'max_depth': 5}, mean: 0.64766, std: 0.00887, params: {'n_estimators': 300, 'max_depth': 5}, mean: 0.65951, std: 0.00896, params: {'n_estimators': 100, 'max_depth': 8}, mean: 0.65967, std: 0.00806, params: {'n_estimators': 120, 'max_depth': 8}, mean: 0.66071, std: 0.00835, params: {'n_estimators': 300, 'max_depth': 8}]\n",
      "roc_auc\n",
      "make_scorer(roc_auc_score, needs_threshold=True)\n"
     ]
    }
   ],
   "source": [
    "print gs.best_estimator_\n",
    "print gs.best_params_\n",
    "print gs.best_score_\n",
    "print gs.cv\n",
    "\n",
    "print gs.error_score\n",
    "print gs.grid_scores_\n",
    "print gs.scoring\n",
    "print gs.scorer_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "\n",
    "print gs.best_params_\n",
    "print gs.best_score_\n",
    "print gs.score\n",
    "\n",
    "\n",
    "print '*'*50 + 'METRICS'+ '*'*50\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print '*'*50 + 'classification_report'+ '*'*50\n",
    "print(classification_report(y_true, y_pred))\n",
    "print '*'*100\n",
    "print '*'*50 + 'confusion_matrix'+ '*'*50\n",
    "print '-'*100\n",
    "print confusion_matrix(y_true, y_pred)\n",
    "print '*'*100\n",
    "print '*'*50 + 'acccuracy Score'+ '*'*50\n",
    "print accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13.13  22.1   26.62  30.02  33.1   35.9   38.36  40.65  42.79  44.89\n",
      "  46.74  48.53  50.27  51.96  53.6   55.19  56.76  58.32  59.79  61.25\n",
      "  62.7   64.13  65.56  66.98  68.38  69.76  71.12  72.47  73.81  75.13\n",
      "  76.43  77.69  78.94  80.16  81.33  82.47  83.53  84.58  85.59  86.58]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1932f198>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAECCAYAAAAB2kexAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdf05c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Scaling the values\n",
    "X = scale(X_train)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=40)\n",
    "pca.fit(X)\n",
    "\n",
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "print var1\n",
    "\n",
    "plt.plot(var1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.60401903 -2.11001815  1.82121627 ..., -0.38061669 -0.48025709\n",
      "  -0.4497662 ]\n",
      " [ 3.29969831 -3.22707177  3.18248643 ..., -1.58531829  3.49152458\n",
      "  -0.7725086 ]\n",
      " [-0.8675456  -2.95158199 -1.29966741 ...,  1.84081625  2.33058855\n",
      "   0.81104952]\n",
      " ..., \n",
      " [ 2.21664014  4.01854979 -1.08888997 ...,  1.62718152 -0.39098247\n",
      "   1.94740606]\n",
      " [-0.92469129  4.86054335 -0.68119381 ...,  0.11800843  0.2839804\n",
      "  -0.44055948]\n",
      " [-1.11869802 -2.78703178 -2.35127564 ...,  0.95842868  0.81237627\n",
      "  -0.03627837]]\n"
     ]
    }
   ],
   "source": [
    "#Looking at above plot I'm taking 30 variables\n",
    "pca = PCA(n_components=34)\n",
    "pca.fit(X)\n",
    "X1=pca.fit_transform(X)\n",
    "\n",
    "print X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16337323, -0.38090235, -0.68963341, ...,  0.85816948,\n",
       "        -0.61725265, -0.2005935 ],\n",
       "       [ 1.19525815,  2.38543011,  0.43460608, ...,  0.85816948,\n",
       "        -0.61725265, -0.2005935 ],\n",
       "       [-0.49141254, -0.32329027, -0.05249353, ..., -1.165271  ,\n",
       "         2.03971475, -0.2005935 ],\n",
       "       ..., \n",
       "       [-0.18173617, -0.13140869, -0.26501517, ...,  0.85816948,\n",
       "        -0.61725265,  4.98520633],\n",
       "       [-0.64647742, -0.89084075, -0.69005846, ...,  0.85816948,\n",
       "        -0.61725265, -0.2005935 ],\n",
       "       [-0.16496015, -0.11902923,  0.5850714 , ..., -1.165271  ,\n",
       "         2.03971475, -0.2005935 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
